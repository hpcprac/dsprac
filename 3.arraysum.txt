name of the file - arr_sum.c

#include <mpi.h>
#include <stdio.h>
#include <stdlib.h>

#define ARRAY_SIZE 16

int main(int argc, char** argv) {
  int rank, size;
  int sum = 0;
  int array[ARRAY_SIZE];

  // Initialize MPI
  MPI_Init(&argc, &argv);
  MPI_Comm_rank(MPI_COMM_WORLD, &rank);
  MPI_Comm_size(MPI_COMM_WORLD, &size);

  // Populate the array on the root process
  if (rank == 0) {
    for (int i = 0; i < ARRAY_SIZE; i++) {
      array[i] = i + 1;
    }
  }

  // Scatter the array to all processes
  int subarray_size = ARRAY_SIZE / size;
  int subarray[subarray_size];
  MPI_Scatter(array, subarray_size, MPI_INT, subarray, subarray_size, MPI_INT, 0, MPI_COMM_WORLD);

  // Sum the local elements
  int local_sum = 0;
  for (int i = 0; i < subarray_size; i++) {
    local_sum += subarray[i];
  }

  // Display the local sum of each process
  printf("Process %d local sum is %d\n", rank, local_sum);

  // Reduce the local sums to get the final sum on the root process
  MPI_Reduce(&local_sum, &sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);

  // Print the result on the root process
  if (rank == 0) {
    printf("The sum of the elements is %d\n", sum);
  }

  // Finalize MPI
  MPI_Finalize();
  return 0;
}





name of the file arr_sum_mp1.c


#include<stdio.h>
#include<mpi.h>
#define arr_size 15
int main(int argc, char *argv[]){
	int rank, size;
	MPI_Init(&argc, &argv);
	MPI_Comm_rank(MPI_COMM_WORLD, &rank);
	MPI_Comm_size(MPI_COMM_WORLD, &size);
	//Code that will execute inside process 0 or rank 0
	if(rank == 0){
		int arr[]= {12,4,6,3,21,15,3,5,7,8,9,1,5,3,5};
		int global_sum = 0, local_sum = 0, recv_local_sum;
		//If the array size is perfectly divisible by number of process.
		if(arr_size%size == 0){
			int array_element_per_process = arr_size/size;
			int sub_arr[array_element_per_process];
			for(int i=1; i<size; i++){
				//Copying the sub array
				for(int j=0; j<array_element_per_process;j++){
					sub_arr[j] = arr[i*array_element_per_process+j];
				}			
				//Sending array chunk of equal size to all the process.
				MPI_Send(sub_arr, array_element_per_process, MPI_INT, i, 1, MPI_COMM_WORLD);
				MPI_Send(&array_element_per_process, 1, MPI_INT, i, 1, MPI_COMM_WORLD);
			}
			//Calculating the local sum of rank 0 itself
			for(int j=0; j<array_element_per_process; j++){
				local_sum += arr[j];
			}
			printf("Rank %d: local sum: %d\n", rank, local_sum);
			global_sum += local_sum;
		//When the array size is not perfectly divisible by number of process.	
		}else{
			int array_element_per_process = arr_size/size + 1;
			int sub_arr[array_element_per_process];
			for(int i=1; i<size; i++){
				if(i == size - 1){
					//last sub array will have the size less than other process array size
					int total_array_size_of_last_process = arr_size - array_element_per_process * i;
					for(int j=0; j< total_array_size_of_last_process; j++){
						sub_arr[j] = arr[i*array_element_per_process+j];
					}
					MPI_Send(&sub_arr, total_array_size_of_last_process, MPI_INT, i, 1, MPI_COMM_WORLD);
					MPI_Send(&total_array_size_of_last_process, 1, MPI_INT, i, 1, MPI_COMM_WORLD);
				}else{
					//Copying the sub array
					for(int j=0; j<array_element_per_process;j++){
						sub_arr[j] = arr[i*array_element_per_process+j];
					}				
					MPI_Send(&sub_arr, array_element_per_process, MPI_INT, i, 1, MPI_COMM_WORLD);
					MPI_Send(&array_element_per_process, 1, MPI_INT, i, 1, MPI_COMM_WORLD);
				}
			}
			//Calculating the local sum of rank 0 itself
			for(int j=0; j<array_element_per_process; j++){
				local_sum += arr[j];
			}
			printf("Rank %d: local sum: %d\n", rank, local_sum);
			global_sum += local_sum;
		}
		//calculating the global sum of the array
		//Receving the local sum from the other process and updating the global sum
		for(int i=1; i<size; i++){
			MPI_Recv(&recv_local_sum, 1, MPI_INT, i, 1, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
			global_sum += recv_local_sum;
		}
		//Printing the output
		printf("The sum of the array is %d\n", global_sum);
	//Code that will get executed inside other than process 0 or rank 0.
	}else{
		//The other process will receive the chunck of array
		int array_element_per_process = arr_size/size + 1;
		int recv_sub_arr[array_element_per_process];
		int recv_array_element_per_process, local_sum = 0;

		MPI_Recv(recv_sub_arr, recv_array_element_per_process, MPI_INT, 0, 1, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
		MPI_Recv(&recv_array_element_per_process, 1, MPI_INT, 0, 1, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
		//Calculating local sum for the sub array
		for(int j=0; j<recv_array_element_per_process; j++){
			local_sum += recv_sub_arr[j];
		}
		//Printing the local sum
		printf("Rank %d: local sum: %d\n", rank, local_sum);
		//Sending back the local sum to the rank 0 or process 0.
		MPI_Send(&local_sum, 1, MPI_INT, 0, 1, MPI_COMM_WORLD);
	}
	MPI_Finalize();
	return 0;
}












steps 
1: run the command "mpicc arr_sum.c -o mpi_sum"
2: run the command "mpirun -np 4 ./mpi_sum"





//explaination for arr_sum_mpi.c



The code demonstrates parallel computation using the Message Passing Interface (MPI) library to calculate the sum of elements in an array. It utilizes multiple processes to perform the computation.

- The array size is defined as 15 using `#define arr_size 15`.
- The program initializes the MPI environment and retrieves the rank and size of the current process using `MPI_Init`, `MPI_Comm_rank`, and `MPI_Comm_size`.
- If the process is rank 0, it divides the array into chunks and distributes them to other processes using `MPI_Send`.
- Rank 0 also calculates the local sum for its own chunk of the array and receives local sums from other processes using `MPI_Recv`.
- Finally, it calculates the global sum by adding up the local sums and outputs the result.
- For processes other than rank 0, they receive their respective array chunks using `MPI_Recv`.
- Each process calculates the local sum for its chunk and sends it back to rank 0 using `MPI_Send`.

The code demonstrates how to distribute work among multiple processes and perform parallel computations using MPI, specifically to compute the sum of an array.




explaination for arr_sum.c

The code demonstrates parallel computation using MPI to calculate the sum of elements in an array. Here's a summary:

- The code initializes the MPI environment and retrieves the rank and size of the current process using `MPI_Init`, `MPI_Comm_rank`, and `MPI_Comm_size`.

- An array of size `ARRAY_SIZE` is declared.

- If the process is rank 0, it populates the array with values.

- The array is scattered to all processes using `MPI_Scatter`.

- Each process calculates the sum of its local elements.

- The local sums of each process are displayed.

- The local sums are reduced to compute the final sum on the root process using `MPI_Reduce` with `MPI_SUM` operation.

- The root process prints the final sum.

- The MPI environment is finalized using `MPI_Finalize`.

This code showcases the usage of MPI for parallel computation by distributing work across processes and aggregating results.


